{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36c34af-36e8-483f-90dd-bc10634ebbd2",
   "metadata": {
    "id": "e36c34af-36e8-483f-90dd-bc10634ebbd2",
    "tags": []
   },
   "source": [
    "# AAI30001 Small Project\n",
    "#### **Group: SP_8**\n",
    " - Chua Chen Yi (2302822)\n",
    " - Wong Jun Jai (2302765)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee5ec1-a889-4910-a57a-014952aabfb8",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318d2a8-30c2-4751-81b4-04d809b39d35",
   "metadata": {
    "id": "1318d2a8-30c2-4751-81b4-04d809b39d35",
    "tags": []
   },
   "source": [
    "#### Our proposed method of improving accuracy over the baseline score is as follows:\n",
    "### 1. Identify a pre-trained model to be our baseline for fine-tuning\n",
    "- Before starting our search, we manually re-created the same testing environment as the sample code. This included splitting the dataset into training, validation and testing identically to the sample. In addition, the use of the TestUA for determining overall performance was use\n",
    "    - *Minor note: We have noticed the way the dataset is split for testing is not the same as how it is described in the text. For example, the test set should only contain files from 'Ses01F' and only from the female speaker. However, checking the dataset class showed that this is not true.*\n",
    "- With a simple evaluation pipeline in placee, we randomly choose 10 different models publically availble from hugging face, and proceeded to score them. They scored a range from 0.60-0.80 on the test dataset.\n",
    "- We decided to use the same base model: **\"facebook/wav2vec2-base\"** with the goal of fine tuning according to the rules and achieve at least 0.70\n",
    "### 2. Perform Data Augmentation On Dataset\n",
    "- #### Augmentation 1\n",
    "    - Details\n",
    "- #### Augmentation 2\n",
    "    - Details\n",
    "### 3. Identify Strengths & Weakness of Pre-Trained Model\n",
    "- We started by training the model for a few epochs to get a general idea of how it performs. A sample confusion matrix is shown here:\n",
    "\n",
    "             A   H    N   S\n",
    "        A  103   8   35   1\n",
    "        H    8  79   36   9\n",
    "        N    2   7  109  53 <- Highest Error\n",
    "        S    1   8   10  59\n",
    "        \n",
    "    In general, the model is able to differentiate angry and happy emotions with a high degree of accuracy. However, the model is not good at differentiaing between neutral and sad emotions. Its greatest weakness is predicting a neutral emotion as a sad one\n",
    "                \n",
    "### 4. Use Secondary Model With Text Embeddings\n",
    "- We have decided not to use extracted text embeddings as a feature of our first model, but instead have a completely seperate model extract and perform sentiment analysis on the text. The final prediction will be a combination of both models.\n",
    "    - This method allows us to:\n",
    "        1. Manage our time better as work can be done to improve the performance of both indepenently.\n",
    "        2. Change our base model if we find a better one.\n",
    "        3. Choose more sophisticated speech-to-text and sentiment analysis models\n",
    "### 5. Develop Algorithm To Merge Predictions\n",
    "- Our final implementation consist of getting the confidence for each label using softmax in addition to its original prediction. The predictions for the 2nd model is then merged into a single CSV file. An gridsearch-like function will identify the optimal parameters *(highlighted in **Bold**)*.\n",
    "- All models tested have improved scores. In general, models with <0.65 score will see a boost of 2-4%, while models >0.65 score will gain 0-2%. \n",
    "    ### Merge Algorithm\n",
    "    - The algorithm that determines the final predictions is a combination of 3 different strategies:\n",
    "        1. **Merging Strategy:** When to rely on the 2nd model?\n",
    "        2. **Prediction Strategy:** How to rely on the 2nd model?\n",
    "        3. **Mapping Strategy:** How to map sentiment to emotions?\n",
    "    ### 5A. Merging Strategy\n",
    "    We have identified 2 possible metrics to decide when to rely on the 2nd model\n",
    "    - **Entrophy Threshold**\n",
    "    We apply a calculate the entrophy based on the 4 confidence scores, following the logic that a lower overall entrophy will mean the model is most confident in its prediction. We will refer to the 2nd model when the entrophy is above the ***entrophy_threshold***.\n",
    "    - **Argmax Threshold**\n",
    "    We apply a simple argmax on the 4 confidence scores. If the value is below the ***argmax_threshold***, we will refer to the 2nd model for the final prediction\n",
    "    ### 5B. Prediction Strategy\n",
    "    We have identified 3 possible metrics to decide how to rely on the 2nd model\n",
    "    - **Default**\n",
    "    Prefer prediction of 2nd model in all situations\n",
    "    - **Ignore**\n",
    "    We identified the original model is very good at angry and happy emotions. So we always prefer the orignal model's predictions if it detects angry or happy\n",
    "    - **Ignore When Match**\n",
    "    If both models agree on the same prediction, we ignore however low the confidence is and assume is correct\n",
    "    ### 5C. Mapping Strategy\n",
    "    Because our sentiment analysis outputs 3 classes, while we have 4 emotions, we ill need to map 1 class to 2 emotions. This corresponds to the 'Negative' sentiment being mapped to either 'Angry' or 'Sad'. We have implemented the following methods:\n",
    "    - **Simple Mapping**\n",
    "    We decide on a ***sentiment_threshold*** value, where anything above is 'Sad'. This can also ***fliped*** around, ie. anything above is 'Angry' as there is no defined way to map the negative sentiment\n",
    "    - **Reference Mapping**\n",
    "    When a negative sentiment needs to be mapped, the confidence of 'Sad' and 'Angry' from the original model is looked up, and Argmax is used to return the most likely emotion.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a8afa-a060-474a-a9c1-bca043d86fbc",
   "metadata": {
    "id": "e30a8afa-a060-474a-a9c1-bca043d86fbc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde82fd-3910-4082-a9f5-d235b19315f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AAI3001",
   "language": "python",
   "name": "aai3001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
